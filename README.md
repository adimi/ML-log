# ML-log
The SQL schema depicted below comprises three areas of information: (i) dataset info, (ii) experiment/single run context and result and (iii) algorithmic details.

## 1. Dataset info
Descriptive information of the dataset comprises general information and feature specific information. The general information of the dataset includes file name, file location, dataset source and basic characteristics, such as number of samples and features, as well as whether samples are classified. For each feature, its name and order in the dataset is given. In addition, the type of the feature, the number of null values and some insights on the distribution and density of the feature are also reported.

### Info population:
This information is supposed to be given upon import of the specific dataset through an automatic analysis process and additional manual input of descriptive attributes. 

## 2. Experiment/single run context and result
Each time a model is trained on a particular dataset, some basic information of the experiment, its context and result is reported. For each experiment, a description maybe given, a reference to the algorithmic approach, information about the system setup and its context. The context is relevant with the scope of the training, e.g. the relevant project or task. For each trining, the relevant quality measures form the result of the experiment, i.e., accuracy, F1 measure, mean squared error etc.

### Info population:
The descriptive information and the context can be hardcoded in the training process. The relevnt information can be populated automatically every time a training in the same context is executed. The result information is directly given by the trainings output.

## 3. Algorithmic details
A training process is formed by a preprocessing and a learning step, both reported in the related experiment. Each one of these, is modeled as a sequence of algorithmic steps. For each algorithm, its name, its order of execution and its parameters are recorded.

### Info population:
The information can be automatically generated by the ML script, based on the components used in the pipeline.

